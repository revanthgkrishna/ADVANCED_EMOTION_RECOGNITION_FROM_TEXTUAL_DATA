{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-1-_1iU_HfwT",
    "outputId": "875aef70-11c8-4a2b-fc41-138c7ab15e10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import os\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "yqdk6x3MzyOw"
   },
   "outputs": [],
   "source": [
    "class EmotionClassifier(nn.Module):\n",
    "    def __init__(self, num_labels=28):\n",
    "        super().__init__()\n",
    "        self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.classifier = nn.Linear(768, num_labels)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        output = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled = output.last_hidden_state[:, 0]\n",
    "        pooled = self.dropout(pooled)\n",
    "        return self.classifier(pooled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xfZ9SLZ_0O_5",
    "outputId": "e044c0de-ac7a-4e0c-a33c-f484c940389d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EmotionClassifier(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=12, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Paths\n",
    "drive_path = \"/content/drive/MyDrive/Project/models\"\n",
    "general_model_paths = [f\"{drive_path}/bert_fold_{i}.pt\" for i in range(1, 6)]\n",
    "rare_model_path = f\"{drive_path}/rare_emotion_model.pt\"\n",
    "\n",
    "# Loading the models\n",
    "general_models = []\n",
    "for path in general_model_paths:\n",
    "    model = EmotionClassifier(num_labels=28).to(device)\n",
    "    model.load_state_dict(torch.load(path, map_location=device))\n",
    "    model.eval()\n",
    "    general_models.append(model)\n",
    "\n",
    "# Loading rare model\n",
    "rare_model = EmotionClassifier(num_labels=12).to(device)\n",
    "rare_model.load_state_dict(torch.load(rare_model_path, map_location=device))\n",
    "rare_model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B4IQrKhW0Tbw"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Defining Rare emotions\n",
    "RARE_EMOTIONS = [\n",
    "    'grief', 'relief', 'curiosity', 'realization', 'pride', 'nervousness',\n",
    "    'confusion', 'caring', 'disappointment', 'annoyance', 'approval', 'disapproval'\n",
    "]\n",
    "\n",
    "ALL_EMOTIONS = [\n",
    "    \"admiration\", \"amusement\", \"anger\", \"annoyance\", \"approval\", \"caring\", \"confusion\", \"curiosity\", \"desire\",\n",
    "    \"disappointment\", \"disapproval\", \"disgust\", \"embarrassment\", \"excitement\", \"fear\", \"gratitude\", \"grief\", \"joy\",\n",
    "    \"love\", \"nervousness\", \"optimism\", \"pride\", \"realization\", \"relief\", \"remorse\", \"sadness\", \"surprise\", \"neutral\"\n",
    "]\n",
    "\n",
    "rare_indices = [ALL_EMOTIONS.index(e) for e in RARE_EMOTIONS]\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_dir = \"/content/drive/MyDrive/Project/models\"\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "def load_general_model(path):\n",
    "    model = EmotionClassifier(num_labels=28)  # matches how you trained/saved\n",
    "    model.load_state_dict(torch.load(path, map_location=device))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "general_models = [load_general_model(f\"{model_dir}/bert_fold_{i}.pt\") for i in range(1, 6)]\n",
    "\n",
    "class RareEmotionClassifier(torch.nn.Module):\n",
    "    def __init__(self, num_labels):\n",
    "        super().__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.dropout = torch.nn.Dropout(0.3)\n",
    "        self.classifier = torch.nn.Linear(768, num_labels)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        return self.classifier(self.dropout(outputs.pooler_output))\n",
    "\n",
    "rare_model = RareEmotionClassifier(num_labels=len(RARE_EMOTIONS))\n",
    "rare_model.load_state_dict(torch.load(f\"{model_dir}/rare_emotion_model.pt\", map_location=device))\n",
    "rare_model.to(device)\n",
    "rare_model.eval()\n",
    "\n",
    "def encode_batch(texts, max_len=128):\n",
    "    encodings = tokenizer(texts, truncation=True, padding=True, return_tensors=\"pt\", max_length=max_len)\n",
    "    return {k: v.to(device) for k, v in encodings.items()}\n",
    "\n",
    "# Ensemble prediction function\n",
    "def ensemble_predict(texts, alpha=0.5):\n",
    "    inputs = encode_batch(texts)\n",
    "\n",
    "    # General logits from all 5 models\n",
    "    general_logits = [model(inputs[\"input_ids\"], inputs[\"attention_mask\"]) for model in general_models]\n",
    "    general_logits = torch.stack(general_logits).mean(dim=0)  # shape: [B, 28]\n",
    "\n",
    "    # Rare logits (12)\n",
    "    rare_logits = rare_model(inputs[\"input_ids\"], inputs[\"attention_mask\"])  # shape: [B, 12]\n",
    "\n",
    "    # Blending general + rare logits for rare indices\n",
    "    final_logits = general_logits.clone()\n",
    "    for i, rare_idx in enumerate(rare_indices):\n",
    "        final_logits[:, rare_idx] = (1 - alpha) * general_logits[:, rare_idx] + alpha * rare_logits[:, i]\n",
    "\n",
    "    probs = torch.sigmoid(final_logits)\n",
    "\n",
    "    # Updated per-label thresholds \n",
    "    thresholds = torch.tensor([\n",
    "        0.60, 0.60, 0.55, 0.60, 0.60, 0.60, 0.60, 0.60, 0.60, 0.60,\n",
    "        0.60, 0.60, 0.65, 0.60, 0.60, 0.60, 0.60, 0.60, 0.60, 0.60,\n",
    "        0.60, 0.60, 0.60, 0.60, 0.60, 0.60, 0.60, 0.60\n",
    "    ]).to(probs.device)\n",
    "\n",
    "    preds = (probs > thresholds).int()\n",
    "\n",
    "    return preds.detach().cpu().numpy(), probs.detach().cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O74_JmcW7zBh",
    "outputId": "7a1e70a4-f597-4720-f288-698c7c0198ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text: I feel completely hopeless and broken\n",
      "\n",
      "  admiration     : 0.520 \n",
      "  amusement      : 0.557 \n",
      "  anger          : 0.585 \n",
      "  annoyance      : 0.516 \n",
      "  approval       : 0.505 \n",
      "  caring         : 0.531 \n",
      "  curiosity      : 0.559 \n",
      "  disgust        : 0.500 \n",
      "  fear           : 0.537 \n",
      "  grief          : 0.525 \n",
      "  joy            : 0.511 \n",
      "  nervousness    : 0.511 \n",
      "  optimism       : 0.523 \n",
      "  pride          : 0.545 \n",
      "  relief         : 0.507 \n",
      "  remorse        : 0.505 \n",
      "\n",
      "Text: I'm so proud of my achievement!\n",
      "\n",
      "  admiration     : 0.501 \n",
      "  caring         : 0.517 \n",
      "  curiosity      : 0.516 \n",
      "  desire         : 0.523 \n",
      "  disappointment : 0.541 \n",
      "  love           : 0.535 \n",
      "  nervousness    : 0.508 \n",
      "  optimism       : 0.560 \n"
     ]
    }
   ],
   "source": [
    "def print_ensemble_results(texts, preds, probs, thresholds, top_k=3):\n",
    "    for i, text in enumerate(texts):\n",
    "        print(f\"\\nText: {text}\\n\")\n",
    "        count = 0\n",
    "        for j in range(len(ALL_EMOTIONS)):\n",
    "            if probs[i][j] >= thresholds[j]:\n",
    "                print(f\"  {ALL_EMOTIONS[j]:<15}: {probs[i][j]:.3f} \")\n",
    "                count += 1\n",
    "\n",
    "        if count == 0:\n",
    "            print(f\"  No emotions above threshold! Showing top {top_k} anyway:\")\n",
    "            top_indices = probs[i].argsort()[-top_k:][::-1]\n",
    "            for idx in top_indices:\n",
    "                print(f\"  {ALL_EMOTIONS[idx]:<15}: {probs[i][idx]:.3f} \")\n",
    "\n",
    "# Thresholds\n",
    "thresholds = torch.tensor([\n",
    "    max(0.5, t) for t in [\n",
    "        0.11, 0.41, 0.22, 0.15, 0.10, 0.10, 0.11, 0.18, 0.10, 0.10,\n",
    "        0.21, 0.12, 0.60, 0.14, 0.10, 0.60, 0.10, 0.11, 0.10, 0.10,\n",
    "        0.18, 0.28, 0.13, 0.14, 0.10, 0.11, 0.10, 0.16\n",
    "    ]\n",
    "]).to(probs.device)\n",
    "\n",
    "texts = [\"I feel completely hopeless and broken\", \"I'm so proud of my achievement!\"]\n",
    "preds, probs = ensemble_predict(texts)\n",
    "print_ensemble_results(texts, preds, probs,thresholds)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
